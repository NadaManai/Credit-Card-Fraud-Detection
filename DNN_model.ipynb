{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc05ba0e-dcef-4d04-ad5f-54f81bf4d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as stats\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import missingno as msno\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import skew, shapiro\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import shap\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve, auc, f1_score, mean_squared_error,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif,chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import xgboost as xgb\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import lightgbm as lgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a732f8-4915-4c86-b925-ea7c22cdd504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "train_df = pd.read_csv('C:/Users/Mega-Pc/Freelance/data/train_df_cleaned.csv', delimiter=',', encoding='utf-8',index_col=0)\n",
    "test_df = pd.read_csv('C:/Users/Mega-Pc/Freelance/data/test_df_cleaned.csv', delimiter=',', encoding='utf-8',index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda0079-4dd8-4c73-aa9c-97a55cf54156",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82972d22-43f8-4108-8ccf-3f24d127f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['is_fraud'])  \n",
    "y_train = train_df['is_fraud']  \n",
    "\n",
    "X_test = test_df.drop(columns=['is_fraud'])  \n",
    "y_test = test_df['is_fraud']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582873df-bb7f-4cd7-885b-6799d05e74cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(zip(np.unique(y_train), class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2dcc5-aed2-4e00-92e9-6746b2318f7f",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f3a98-9c52-49ac-b62c-ea469f9411b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, confusion_matrix, \n",
    "    precision_recall_curve, auc, f1_score, matthews_corrcoef\n",
    ")\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, threshold_plot=False):\n",
    "    # Predict probabilities\n",
    "    y_train_proba = model.predict(X_train).flatten()\n",
    "    y_train_pred = (y_train_proba >= 0.5).astype(int)\n",
    "\n",
    "    y_test_proba = model.predict(X_test).flatten()\n",
    "    y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    overall_accuracy = accuracy_score(np.concatenate([y_train, y_test]), \n",
    "                                      np.concatenate([y_train_pred, y_test_pred]))\n",
    "\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    g_mean = geometric_mean_score(y_test, y_test_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"\\033[1;34mAlgorithm: Neural Network\\033[0m\")\n",
    "    print(\"\\n\\033[1;32mClassification Report:\\033[0m\\n\", classification_report(y_test, y_test_pred, target_names=[\"No Churn\", \"Churn\"]))\n",
    "    print(f\"\\033[1;36mTraining Accuracy:\\033[0m {train_accuracy:.4f}\")\n",
    "    print(f\"\\033[1;36mTest Accuracy:\\033[0m {test_accuracy:.4f}\")\n",
    "    print(f\"\\033[1;36mOverall Accuracy:\\033[0m {overall_accuracy:.4f}\")\n",
    "    print(f\"\\033[1;35mF1 Score:\\033[0m {f1:.4f}\")\n",
    "    print(f\"\\033[1;35mG-Mean:\\033[0m {g_mean:.4f}\")\n",
    "    print(f\"\\033[1;35mMatthews Correlation Coefficient (MCC):\\033[0m {mcc:.4f}\")\n",
    "\n",
    "    precision_train, recall_train, _ = precision_recall_curve(y_train, y_train_proba)\n",
    "    pr_auc_train = auc(recall_train, precision_train)\n",
    "\n",
    "    precision_test, recall_test, _ = precision_recall_curve(y_test, y_test_proba)\n",
    "    pr_auc_test = auc(recall_test, precision_test)\n",
    "\n",
    "    recall_combined = np.concatenate([recall_train, recall_test])\n",
    "    precision_combined = np.concatenate([precision_train, precision_test])\n",
    "    sorted_indices = np.argsort(recall_combined)\n",
    "    recall_combined = recall_combined[sorted_indices]\n",
    "    precision_combined = precision_combined[sorted_indices]\n",
    "\n",
    "    print(f\"\\033[1;31mTraining Precision-Recall AUC:\\033[0m {pr_auc_train:.4f}\")\n",
    "    print(f\"\\033[1;31mTest Precision-Recall AUC:\\033[0m {pr_auc_test:.4f}\")\n",
    "    print(f\"\\033[1;31mOverall Precision-Recall AUC:\\033[0m {auc(recall_combined, precision_combined):.4f}\")\n",
    "\n",
    "    trace1 = go.Scatter(x=recall_test, y=precision_test, name=\"Test Precision-Recall Curve\",\n",
    "                        line=dict(color='blue', width=3),\n",
    "                        hovertemplate='<b>Recall:</b> %{x}<br><b>Precision:</b> %{y}')\n",
    "    trace2 = go.Scatter(x=recall_train, y=precision_train, name=\"Train Precision-Recall Curve\",\n",
    "                        line=dict(color='green', width=3),\n",
    "                        hovertemplate='<b>Recall:</b> %{x}<br><b>Precision:</b> %{y}')\n",
    "    trace3 = go.Scatter(x=recall_combined, y=precision_combined, name=\"Overall Precision-Recall Curve\",\n",
    "                        line=dict(color='purple', width=3, dash='dot'),\n",
    "                        hovertemplate='<b>Recall:</b> %{x}<br><b>Precision:</b> %{y}')\n",
    "    trace4 = go.Scatter(x=[0, 1], y=[1, 0], name=\"Random Chance\",\n",
    "                        line=dict(color='red', dash='dash', width=2))\n",
    "\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    heatmap = go.Heatmap(\n",
    "        z=conf_matrix,\n",
    "        x=[\"No Churn\", \"Churn\"],\n",
    "        y=[\"No Churn\", \"Churn\"],\n",
    "        colorscale=[\n",
    "            [0.0, \"#FFF7EC\"],\n",
    "            [0.33, \"#FDBB84\"],\n",
    "            [0.66, \"#FC8D59\"],\n",
    "            [1.0, \"#D7301F\"]\n",
    "        ],\n",
    "        zmin=0,\n",
    "        zmax=conf_matrix.max(),\n",
    "        colorbar=dict(title=\"Count\"),\n",
    "        hovertemplate=\"True Class: %{y}<br>Predicted: %{x}<br>Count: %{z}<extra></extra>\",\n",
    "        showscale=True\n",
    "    )\n",
    "\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Confusion Matrix',\n",
    "            'Precision-Recall Curve'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(heatmap, row=1, col=1)\n",
    "    fig.add_trace(trace1, row=1, col=2)\n",
    "    fig.add_trace(trace2, row=1, col=2)\n",
    "    fig.add_trace(trace3, row=1, col=2)\n",
    "    fig.add_trace(trace4, row=1, col=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        showlegend=True,\n",
    "        title=\"Model Performance\",\n",
    "        autosize=True,\n",
    "        height=500, width=1000,\n",
    "        plot_bgcolor='rgba(240,240,240,0.95)',\n",
    "        paper_bgcolor='rgba(240,240,240,0.95)',\n",
    "        font=dict(family=\"Arial\", size=12),\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Predicted Labels\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Actual Labels\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Recall\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Precision\", row=1, col=2)\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a8a89-c14d-4226-9e39-9887896e872b",
   "metadata": {},
   "source": [
    "## Deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0158a1e-7779-443d-b85e-c23c4e5ec6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186100aa-6f62-4823-a93a-2974727fbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- CLASS WEIGHTS ---\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights_dict = dict(zip(classes, class_weights))\n",
    "print(\"Class Weights:\", class_weights_dict)\n",
    "\n",
    "# --- MODEL DEFINITION ---\n",
    "dnn = Sequential([\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001), input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(16, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# --- COMPILE ---\n",
    "dnn.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# --- TRAIN ---\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history = dnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.1,  # small validation from train\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- TEST EVALUATION ---\n",
    "predictions = dnn.predict(X_test)\n",
    "binary_preds = (predictions >= 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, binary_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c651b-c427-4515-8388-cfb65731439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe8c11-9fe1-4337-8c85-68a4b539974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dnn, X_train, X_test, y_train, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fb72b-0b48-4271-ae83-27dcf334c8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
