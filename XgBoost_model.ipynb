{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e681bede-44b5-4a91-a73a-6868ed2fb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as stats\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.stats import skew, shapiro\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve, auc, f1_score, mean_squared_error,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif,chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import xgboost as xgb\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import lightgbm as lgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "503482d2-6f8a-44c8-90d2-3b774db0c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "train_df = pd.read_csv('C:/Users/Mega-Pc/Freelance/data/train_df_cleaned.csv', delimiter=',', encoding='utf-8',index_col=0)\n",
    "test_df = pd.read_csv('C:/Users/Mega-Pc/Freelance/data/test_df_cleaned.csv', delimiter=',', encoding='utf-8',index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d53120-ef97-4b95-aee5-39153ae417cf",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a66458c-39c2-4e59-a492-179508002cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['is_fraud'])  \n",
    "y_train = train_df['is_fraud']  \n",
    "\n",
    "X_test = test_df.drop(columns=['is_fraud'])  \n",
    "y_test = test_df['is_fraud']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46db886d-39b4-436a-b3ce-8e6cc260ffbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_fraud</th>\n",
       "      <th>fraud_count_merchant</th>\n",
       "      <th>fraud_count_category</th>\n",
       "      <th>fraud_count_job</th>\n",
       "      <th>amt_per_category</th>\n",
       "      <th>dob_year</th>\n",
       "      <th>amt_per_capita</th>\n",
       "      <th>haversine_dist_x_amt</th>\n",
       "      <th>category_code</th>\n",
       "      <th>gender_x_category</th>\n",
       "      <th>...</th>\n",
       "      <th>category_misc_pos</th>\n",
       "      <th>category_personal_care</th>\n",
       "      <th>category_shopping_net</th>\n",
       "      <th>state_CO</th>\n",
       "      <th>state_IN</th>\n",
       "      <th>state_OH</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unix_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000184</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.057940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380490</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.319858</td>\n",
       "      <td>0.138568</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000902</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.068670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430641</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.287066</td>\n",
       "      <td>0.379142</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004250</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280457</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.273982</td>\n",
       "      <td>0.481602</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005879</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348024</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.294928</td>\n",
       "      <td>0.276440</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010388</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.064378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440555</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.332077</td>\n",
       "      <td>0.180526</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.650057</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.611658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.744244</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.255323</td>\n",
       "      <td>0.462979</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.130135</th>\n",
       "      <td>0.621245</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.954936</td>\n",
       "      <td>0.393455</td>\n",
       "      <td>0.359752</td>\n",
       "      <td>0.673938</td>\n",
       "      <td>0.416242</td>\n",
       "      <td>0.398138</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.389883</th>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.446445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.752964</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.269041</td>\n",
       "      <td>0.082395</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.752628</th>\n",
       "      <td>0.476953</td>\n",
       "      <td>0.352485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302070</td>\n",
       "      <td>0.754014</td>\n",
       "      <td>0.714438</td>\n",
       "      <td>0.467038</td>\n",
       "      <td>0.686978</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.219937</th>\n",
       "      <td>0.817573</td>\n",
       "      <td>0.362994</td>\n",
       "      <td>0.487124</td>\n",
       "      <td>0.517796</td>\n",
       "      <td>0.679233</td>\n",
       "      <td>0.878584</td>\n",
       "      <td>0.476410</td>\n",
       "      <td>0.680192</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1104007 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           total_fraud  fraud_count_merchant  fraud_count_category  \\\n",
       "unix_time                                                            \n",
       "0.000184      0.000000              0.111111              0.057940   \n",
       "0.000902      0.000000              0.166667              0.068670   \n",
       "0.004250      0.000000              0.444444              0.244635   \n",
       "0.005879      0.000000              0.000000              0.053648   \n",
       "0.010388      0.000000              0.055556              0.064378   \n",
       "...                ...                   ...                   ...   \n",
       "0.650057      0.473684              0.611658              1.000000   \n",
       "0.130135      0.621245              0.722222              0.954936   \n",
       "0.389883      0.578947              0.446445              1.000000   \n",
       "0.752628      0.476953              0.352485              1.000000   \n",
       "0.219937      0.817573              0.362994              0.487124   \n",
       "\n",
       "           fraud_count_job  amt_per_category  dob_year  amt_per_capita  \\\n",
       "unix_time                                                                \n",
       "0.000184          0.000000          0.380490  0.765432        0.319858   \n",
       "0.000902          0.000000          0.430641  0.765432        0.287066   \n",
       "0.004250          0.000000          0.280457  0.765432        0.273982   \n",
       "0.005879          0.000000          0.348024  0.765432        0.294928   \n",
       "0.010388          0.000000          0.440555  0.765432        0.332077   \n",
       "...                    ...               ...       ...             ...   \n",
       "0.650057          0.966667          0.744244  0.148148        0.255323   \n",
       "0.130135          0.393455          0.359752  0.673938        0.416242   \n",
       "0.389883          0.366667          0.752964  0.938272        0.269041   \n",
       "0.752628          0.302070          0.754014  0.714438        0.467038   \n",
       "0.219937          0.517796          0.679233  0.878584        0.476410   \n",
       "\n",
       "           haversine_dist_x_amt  category_code  gender_x_category  ...  \\\n",
       "unix_time                                                          ...   \n",
       "0.000184               0.138568       0.461538           0.000000  ...   \n",
       "0.000902               0.379142       0.692308           0.000000  ...   \n",
       "0.004250               0.481602       0.153846           0.000000  ...   \n",
       "0.005879               0.276440       0.538462           0.000000  ...   \n",
       "0.010388               0.180526       0.769231           0.000000  ...   \n",
       "...                         ...            ...                ...  ...   \n",
       "0.650057               0.462979       0.846154           0.000000  ...   \n",
       "0.130135               0.398138       0.307692           0.307692  ...   \n",
       "0.389883               0.082395       0.846154           0.000000  ...   \n",
       "0.752628               0.686978       0.846154           0.000000  ...   \n",
       "0.219937               0.680192       0.615385           0.000000  ...   \n",
       "\n",
       "           category_misc_pos  category_personal_care  category_shopping_net  \\\n",
       "unix_time                                                                     \n",
       "0.000184                 0.0                     0.0                    0.0   \n",
       "0.000902                 1.0                     0.0                    0.0   \n",
       "0.004250                 0.0                     0.0                    0.0   \n",
       "0.005879                 0.0                     0.0                    0.0   \n",
       "0.010388                 0.0                     1.0                    0.0   \n",
       "...                      ...                     ...                    ...   \n",
       "0.650057                 0.0                     0.0                    1.0   \n",
       "0.130135                 0.0                     0.0                    0.0   \n",
       "0.389883                 0.0                     0.0                    1.0   \n",
       "0.752628                 0.0                     0.0                    1.0   \n",
       "0.219937                 0.0                     0.0                    0.0   \n",
       "\n",
       "           state_CO  state_IN  state_OH  state_VA  state_WV  state_WY  \\\n",
       "unix_time                                                               \n",
       "0.000184        0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "0.000902        0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "0.004250        0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "0.005879        0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "0.010388        0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "0.650057        0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "0.130135        0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "0.389883        0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "0.752628        0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "0.219937        0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "           is_fraud  \n",
       "unix_time            \n",
       "0.000184          0  \n",
       "0.000902          0  \n",
       "0.004250          0  \n",
       "0.005879          0  \n",
       "0.010388          0  \n",
       "...             ...  \n",
       "0.650057          1  \n",
       "0.130135          1  \n",
       "0.389883          1  \n",
       "0.752628          1  \n",
       "0.219937          1  \n",
       "\n",
       "[1104007 rows x 37 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d0d62-e47c-4d5e-9570-555febfb3e2f",
   "metadata": {},
   "source": [
    "## 🎯 Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6e6c4a3-6a23-4889-9e83-a991ea78cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(zip(np.unique(y_train), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "488ddf3c-0fdd-4055-9a3b-585a630abeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, auc, balanced_accuracy_score, f1_score, recall_score, precision_score, matthews_corrcoef\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def evaluate_model_interactive(model, X_train, X_test, y_train, y_test, threshold_plot=False):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    try:\n",
    "        check_is_fitted(model, \"predict_proba\")\n",
    "        y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            y_train_proba = model.decision_function(X_train)\n",
    "            y_test_proba = model.decision_function(X_test)\n",
    "        except AttributeError:\n",
    "            print(\"Warning: AUC calculation skipped (no probability outputs available)\")\n",
    "            y_train_proba = None\n",
    "            y_test_proba = None\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    overall_accuracy = accuracy_score(np.concatenate([y_train, y_test]), np.concatenate([y_train_pred, y_test_pred]))\n",
    "\n",
    "    balanced_acc_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "    balanced_acc_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    balanced_acc_overall = (balanced_acc_train + balanced_acc_test) / 2\n",
    "\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    g_mean = geometric_mean_score(y_test, y_test_pred)\n",
    "\n",
    "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "    class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}\n",
    "    recalls = recall_score(y_test, y_test_pred, average=None)\n",
    "\n",
    "    wba_train = sum(class_weight_dict[i] * recall_score(y_train, y_train_pred, average=None)[i] for i in range(len(recalls))) / sum(class_weights)\n",
    "    wba_test = sum(class_weight_dict[i] * recalls[i] for i in range(len(recalls))) / sum(class_weights)\n",
    "    wba_overall = (wba_train + wba_test) / 2\n",
    "\n",
    "    mcc = matthews_corrcoef(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"\\033[1;34mAlgorithm:\\033[0m {type(model).__name__}\")\n",
    "    print(\"\\n\\033[1;32mClassification Report:\\033[0m\\n\", classification_report(y_test, y_test_pred, target_names=[\"No Fraud\", \"Fraud\"]))\n",
    "    print(f\"\\033[1;36mTraining Accuracy:\\033[0m {train_accuracy:.4f}\")\n",
    "    print(f\"\\033[1;36mTest Accuracy:\\033[0m {test_accuracy:.4f}\")\n",
    "    print(f\"\\033[1;36mOverall Accuracy:\\033[0m {overall_accuracy:.4f}\")\n",
    "\n",
    "    print(f\"\\033[1;35mG-Mean:\\033[0m {g_mean:.4f}\")\n",
    "    print(f\"\\033[1;35mMatthews Correlation Coefficient (MCC):\\033[0m {mcc:.4f}\")\n",
    "\n",
    "    if y_test_proba is not None:\n",
    "        precision_train, recall_train, _ = precision_recall_curve(y_train, y_train_proba)\n",
    "        pr_auc_train = auc(recall_train, precision_train)\n",
    "\n",
    "        precision_test, recall_test, _ = precision_recall_curve(y_test, y_test_proba)\n",
    "        pr_auc_test = auc(recall_test, precision_test)\n",
    "\n",
    "        recall_combined = np.concatenate([recall_train, recall_test])\n",
    "        precision_combined = np.concatenate([precision_train, precision_test])\n",
    "\n",
    "        sorted_indices = np.argsort(recall_combined)\n",
    "        recall_combined = recall_combined[sorted_indices]\n",
    "        precision_combined = precision_combined[sorted_indices]\n",
    "\n",
    "        print(f\"\\033[1;31mTraining Precision-Recall AUC:\\033[0m {pr_auc_train:.4f}\")\n",
    "        print(f\"\\033[1;31mTest Precision-Recall AUC:\\033[0m {pr_auc_test:.4f}\")\n",
    "        print(f\"\\033[1;31mOverall Precision-Recall AUC:\\033[0m {auc(recall_combined, precision_combined):.4f}\")\n",
    "\n",
    "        trace1 = go.Scatter(\n",
    "            x=recall_test, y=precision_test,\n",
    "            name=\"Test Precision-Recall Curve\",\n",
    "            line=dict(color='blue', width=3),\n",
    "            hovertemplate='<b>Recall:</b> %{x}<br><b>Precision:</b> %{y}'\n",
    "        )\n",
    "\n",
    "        trace2 = go.Scatter(\n",
    "            x=recall_train, y=precision_train,\n",
    "            name=\"Train Precision-Recall Curve\",\n",
    "            line=dict(color='green', width=3),\n",
    "            hovertemplate='<b>Recall:</b> %{x}<br><b>Precision:</b> %{y}'\n",
    "        )\n",
    "\n",
    "        trace3 = go.Scatter(\n",
    "            x=recall_combined, y=precision_combined,\n",
    "            name=\"Overall Precision-Recall Curve\",\n",
    "            line=dict(color='purple', width=3, dash='dot'),\n",
    "            hovertemplate='<b>Recall:</b> %{x}<br><b>Precision:</b> %{y}'\n",
    "        )\n",
    "\n",
    "        trace4 = go.Scatter(\n",
    "            x=[0, 1], y=[1, 0],\n",
    "            name=\"Random Chance\",\n",
    "            line=dict(color='red', dash='dash', width=2)\n",
    "        )\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    heatmap = go.Heatmap(\n",
    "        z=conf_matrix,\n",
    "        x=[\"No fraud\", \"fraud\"],\n",
    "        y=[\"No fraud\", \"fraud\"],\n",
    "        colorscale=[\n",
    "            [0.0, \"#FFF7EC\"],\n",
    "            [0.33, \"#FDBB84\"],\n",
    "            [0.66, \"#FC8D59\"],\n",
    "            [1.0, \"#D7301F\"]\n",
    "        ],\n",
    "        zmin=0,\n",
    "        zmax=conf_matrix.max(),\n",
    "        colorbar=dict(title=\"Count\"),\n",
    "        hovertemplate=\"True Class: %{y}<br>Predicted: %{x}<br>Count: %{z}<extra></extra>\",\n",
    "        showscale=True\n",
    "    )\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Confusion Matrix',\n",
    "            'Precision-Recall Curve'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(heatmap, row=1, col=1)\n",
    "    fig.add_trace(trace1, row=1, col=2)\n",
    "    fig.add_trace(trace2, row=1, col=2)\n",
    "    fig.add_trace(trace3, row=1, col=2)\n",
    "    fig.add_trace(trace4, row=1, col=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        title=\"Model Performance\",\n",
    "        autosize=True,\n",
    "        height=600, width=1000,\n",
    "        plot_bgcolor='rgba(240,240,240,0.95)',\n",
    "        paper_bgcolor='rgba(240,240,240,0.95)',\n",
    "        font=dict(family=\"Arial\", size=12),\n",
    "    )\n",
    "\n",
    "    fig[\"layout\"][\"xaxis1\"].update(title=\"Predicted Labels\")\n",
    "    fig[\"layout\"][\"yaxis1\"].update(title=\"Actual Labels\")\n",
    "    fig[\"layout\"][\"xaxis2\"].update(title=\"Recall\")\n",
    "    fig[\"layout\"][\"yaxis2\"].update(title=\"Precision\")\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abdb345-8f2e-4a7d-8b65-15b711bf944a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #e0f7fa; padding: 20px; border-radius: 10px; font-size: 24px; font-weight: bold; color: #004d40;\">\n",
    "    🌿 Tree Ensembles\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d937af0c-0672-475b-aac6-81abca042722",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b53b61de-5027-42f4-87d7-b962f6e2ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_negative_class = (y_train == 0).sum()  # No FRAUD (Negative Class)\n",
    "num_positive_class = (y_train == 1).sum()  # FRAUD (Positive Class)\n",
    "scale_pos_weight = num_negative_class / num_positive_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aff1e7d-44b0-4c93-a8ad-6c53a316d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 200, 350,step=50) \n",
    "    max_depth = trial.suggest_int('max_depth', 3, 7)  \n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.02) \n",
    "    subsample = trial.suggest_float('subsample', 0.6, 0.8)  \n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.6, 0.8)  \n",
    "    gamma = trial.suggest_float('gamma', 5, 20)  \n",
    "    alpha = trial.suggest_float('alpha', 5, 20)  \n",
    "    lambda_ = trial.suggest_float('lambda', 2, 20)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 5, 20)\n",
    "    \n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        gamma=gamma,\n",
    "        alpha=alpha,\n",
    "        lambda_=lambda_,\n",
    "        min_child_weight=min_child_weight, \n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        use_label_encoder=False,\n",
    "        class_weight=class_weights,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "    \n",
    "    for train_index, val_index in stratified_kfold.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = model.predict_proba(X_val_fold)[:, 1]  \n",
    "        auc_scores.append(roc_auc_score(y_val_fold, y_pred_fold))\n",
    "                          \n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49159715-6b20-46d9-a914-4175e0f531f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 16:04:50,877] A new study created in memory with name: no-name-5744b4ac-ad1b-4587-9e7f-5442abbaca1f\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')  \n",
    "study.optimize(objective, n_trials=10)  \n",
    "\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best trial: {best_trial.params}\")\n",
    "\n",
    "\n",
    "XgBoost = xgb.XGBClassifier(\n",
    "    n_estimators=best_trial.params['n_estimators'],\n",
    "    max_depth=best_trial.params['max_depth'],\n",
    "    learning_rate=best_trial.params['learning_rate'],\n",
    "    subsample=best_trial.params['subsample'],\n",
    "    colsample_bytree=best_trial.params['colsample_bytree'],\n",
    "    gamma=best_trial.params['gamma'],           \n",
    "    alpha=best_trial.params['alpha'],           \n",
    "    lambda_=best_trial.params['lambda'],       \n",
    "    min_child_weight=best_trial.params['min_child_weight'],  \n",
    "    scale_pos_weight=scale_pos_weight, \n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    class_weight=class_weights,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "XgBoost.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f0a5e8-7629-425e-9f5c-828d53b5434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_interactive(\n",
    "    XgBoost, \n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train, \n",
    "    y_test, \n",
    "    threshold_plot=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752c922-2a51-4e0e-8650-34eb3c76e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "save_path = r\"C:\\Users\\Mega-Pc\\Freelance\\data\\xgboost_model.pkl\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(XgBoost, f)\n",
    "\n",
    "print(f\"Model saved at: {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
