{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c77da2f-1356-417b-be28-c3eaad7a7011",
   "metadata": {},
   "source": [
    "<p style=\"background-color: #0055A4; font-size: 48px; font-weight: bold; color: white; padding: 20px; text-align: center;\">\n",
    "ðŸ§¹ Data Cleaning \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eeccbbd-a357-410b-a8de-883d94a36657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as stats\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import missingno as msno\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import skew, shapiro\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import shap\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from prettytable import PrettyTable\n",
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e5ec07-2c78-408b-8356-d3788a5a61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "train_df = pd.read_csv('C:/Users/Mega-Pc/Freelance/data/fraudTrain.csv', delimiter=',', encoding='utf-8',index_col=0)\n",
    "test_df = pd.read_csv('C:/Users/Mega-Pc/Freelance/data/fraudTest.csv', delimiter=',', encoding='utf-8',index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a853c7-cf5f-4ea0-9943-d66d33a84a41",
   "metadata": {},
   "source": [
    "## ðŸ”„ Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d1ab848-1386-4332-a353-44543eff0e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records: 0\n"
     ]
    }
   ],
   "source": [
    "#train_df\n",
    "duplicate_count = train_df.duplicated().sum()\n",
    "print(f'Number of duplicate records: {duplicate_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f9d198e-2a67-4682-b208-d6f02cae58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records: 0\n"
     ]
    }
   ],
   "source": [
    "#train_df\n",
    "duplicate_count = test_df.duplicated().sum()\n",
    "print(f'Number of duplicate records: {duplicate_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d88f733-0e4d-4857-9747-91a108f2e4bc",
   "metadata": {},
   "source": [
    "## âœ¨ Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f26df6-e67c-4ebc-9fff-8a787293e886",
   "metadata": {},
   "source": [
    "## Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b27ee5-d376-446b-a63b-aa5f2c91691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df + test_df\n",
    "skewed_cols = ['amt','city_pop']\n",
    "for col in skewed_cols:\n",
    "    train_df[col] = np.log1p(train_df[col])  \n",
    "    test_df[col] = np.log1p(test_df[col])\n",
    "     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffb65409-e551-4ff2-bb14-e91f326eb822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amt</td>\n",
       "      <td>-0.298852</td>\n",
       "      <td>-0.527247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_pop</td>\n",
       "      <td>0.606094</td>\n",
       "      <td>-0.301258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  Skewness  Kurtosis\n",
       "0       amt -0.298852 -0.527247\n",
       "1  city_pop  0.606094 -0.301258"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "for var in  skewed_cols:\n",
    "    skewness = stats.skew(train_df[var])\n",
    "    kurtosis = stats.kurtosis(train_df[var])\n",
    "    \n",
    "    results.append({\n",
    "        'Feature':  var ,\n",
    "        'Skewness': skewness,\n",
    "        'Kurtosis': kurtosis\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a81ba-fa90-4190-94cc-273b77091610",
   "metadata": {},
   "source": [
    "## Handle outliers by capping them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37972283-18ab-4897-b234-78984b817833",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_vars_filtered = [\n",
    "    \"amt\",\n",
    "    \"zip\",\n",
    "    \"lat\",\n",
    "    \"long\",\n",
    "    \"city_pop\",\n",
    "    \"unix_time\",\n",
    "    \"merch_lat\",\n",
    "    \"merch_long\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5809721-0468-4e5b-a5dc-7e4ca9de817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature   Lower Bound   Upper Bound  Outliers Count  Total Points\n",
      "0         amt -7.348234e-01  7.532865e+00             818       1296675\n",
      "1         zip -4.247050e+04  1.407495e+05               0       1296675\n",
      "2         lat  2.364065e+01  5.292025e+01            4679       1296675\n",
      "3        long -1.217580e+02 -5.519800e+01           49922       1296675\n",
      "4    city_pop  1.650397e+00  1.488145e+01            4168       1296675\n",
      "5   unix_time  1.307799e+09  1.390337e+09               0       1296675\n",
      "6   merch_lat  2.389818e+01  5.279255e+01            4967       1296675\n",
      "7  merch_long -1.218880e+02 -5.524608e+01           41994       1296675\n"
     ]
    }
   ],
   "source": [
    "#train_df\n",
    "outliers_info = []\n",
    "\n",
    "for col in numerical_vars_filtered:\n",
    "    Q1 = train_df[col].quantile(0.25)\n",
    "    Q3 = train_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = train_df[(train_df[col] < lower_bound) | (train_df[col] > upper_bound)]\n",
    "    \n",
    "    outliers_info.append({\n",
    "        'Feature': col,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound,\n",
    "        'Outliers Count': len(outliers),\n",
    "        'Total Points': len(train_df)\n",
    "    })\n",
    "\n",
    "outliers_df = pd.DataFrame(outliers_info)\n",
    "print(outliers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85b89a0a-46ac-411c-aa7c-471fb4097ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[column] = np.clip(df[column], lower_bound, upper_bound)\n",
    "    return df\n",
    "\n",
    "columns_with_outliers = [\n",
    "    \"amt\",\n",
    "    \"lat\",\n",
    "    \"long\",\n",
    "    \"city_pop\",\n",
    "    \"merch_lat\",\n",
    "    \"merch_long\"\n",
    "]\n",
    "\n",
    "for col in columns_with_outliers:\n",
    "    train_df = handle_outliers(train_df, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4ce4f36-8e4e-4b75-a858-151f127f27ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature   Lower Bound   Upper Bound  Outliers Count  Total Points\n",
      "0         amt -7.348234e-01  7.532865e+00               0       1296675\n",
      "1         zip -4.247050e+04  1.407495e+05               0       1296675\n",
      "2         lat  2.364065e+01  5.292025e+01               0       1296675\n",
      "3        long -1.217580e+02 -5.519800e+01               0       1296675\n",
      "4    city_pop  1.650397e+00  1.488145e+01               0       1296675\n",
      "5   unix_time  1.307799e+09  1.390337e+09               0       1296675\n",
      "6   merch_lat  2.389818e+01  5.279255e+01               0       1296675\n",
      "7  merch_long -1.218880e+02 -5.524608e+01               0       1296675\n"
     ]
    }
   ],
   "source": [
    "# results after capping outliers\n",
    "outliers_info = []\n",
    "\n",
    "for col in numerical_vars_filtered:\n",
    "    Q1 = train_df[col].quantile(0.25)\n",
    "    Q3 = train_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = train_df[(train_df[col] < lower_bound) | (train_df[col] > upper_bound)]\n",
    "    \n",
    "    outliers_info.append({\n",
    "        'Feature': col,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound,\n",
    "        'Outliers Count': len(outliers),\n",
    "        'Total Points': len(train_df)\n",
    "    })\n",
    "\n",
    "outliers_df = pd.DataFrame(outliers_info)\n",
    "print(outliers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d6714c6-349d-42b6-bd99-59611ffd6e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature   Lower Bound   Upper Bound  Outliers Count  Total Points\n",
      "0         amt -7.372033e-01  7.531819e+00             402       1296675\n",
      "1         zip -4.228650e+04  1.405895e+05               0       1296675\n",
      "2         lat  2.383005e+01  5.273365e+01            1933       1296675\n",
      "3        long -1.217322e+02 -5.524100e+01           21104       1296675\n",
      "4    city_pop  1.691879e+00  1.480513e+01            1697       1296675\n",
      "5   unix_time  1.361271e+09  1.400625e+09               0       1296675\n",
      "6   merch_lat  2.395701e+01  5.275246e+01            2090       1296675\n",
      "7  merch_long -1.218659e+02 -5.530390e+01           17926       1296675\n"
     ]
    }
   ],
   "source": [
    "#test_df\n",
    "outliers_info = []\n",
    "\n",
    "for col in numerical_vars_filtered:\n",
    "    Q1 = test_df[col].quantile(0.25)\n",
    "    Q3 = test_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = test_df[(test_df[col] < lower_bound) | (test_df[col] > upper_bound)]\n",
    "    \n",
    "    outliers_info.append({\n",
    "        'Feature': col,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound,\n",
    "        'Outliers Count': len(outliers),\n",
    "        'Total Points': len(train_df)\n",
    "    })\n",
    "\n",
    "outliers_df = pd.DataFrame(outliers_info)\n",
    "print(outliers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60b25697-197f-4920-834f-d967dca90328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[column] = np.clip(df[column], lower_bound, upper_bound)\n",
    "    return df\n",
    "\n",
    "columns_with_outliers = [\n",
    "    \"amt\",\n",
    "    \"lat\",\n",
    "    \"long\",\n",
    "    \"city_pop\",\n",
    "    \"merch_lat\",\n",
    "    \"merch_long\"\n",
    "]\n",
    "\n",
    "for col in columns_with_outliers:\n",
    "    train_df = handle_outliers(test_df, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6b52c2b-b59e-403f-90fa-4a5062165820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature   Lower Bound   Upper Bound  Outliers Count  Total Points\n",
      "0         amt -7.372033e-01  7.531819e+00               0        555719\n",
      "1         zip -4.228650e+04  1.405895e+05               0        555719\n",
      "2         lat  2.383005e+01  5.273365e+01               0        555719\n",
      "3        long -1.217322e+02 -5.524100e+01               0        555719\n",
      "4    city_pop  1.691879e+00  1.480513e+01               0        555719\n",
      "5   unix_time  1.361271e+09  1.400625e+09               0        555719\n",
      "6   merch_lat  2.395701e+01  5.275246e+01               0        555719\n",
      "7  merch_long -1.218659e+02 -5.530390e+01               0        555719\n"
     ]
    }
   ],
   "source": [
    "# results after capping outliers\n",
    "outliers_info = []\n",
    "\n",
    "for col in numerical_vars_filtered:\n",
    "    Q1 = test_df[col].quantile(0.25)\n",
    "    Q3 = test_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = test_df[(test_df[col] < lower_bound) | (test_df[col] > upper_bound)]\n",
    "    \n",
    "    outliers_info.append({\n",
    "        'Feature': col,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound,\n",
    "        'Outliers Count': len(outliers),\n",
    "        'Total Points': len(train_df)\n",
    "    })\n",
    "\n",
    "outliers_df = pd.DataFrame(outliers_info)\n",
    "print(outliers_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2699d6-16a7-4350-883c-cf321637e4f5",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16de60dd-523d-451b-b1d8-d759ed9641aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trans_date_trans_time': {'train_unique': 544760, 'test_unique': 544760},\n",
       " 'merchant': {'train_unique': 693, 'test_unique': 693},\n",
       " 'category': {'train_unique': 14, 'test_unique': 14},\n",
       " 'first': {'train_unique': 341, 'test_unique': 341},\n",
       " 'last': {'train_unique': 471, 'test_unique': 471},\n",
       " 'gender': {'train_unique': 2, 'test_unique': 2},\n",
       " 'street': {'train_unique': 924, 'test_unique': 924},\n",
       " 'city': {'train_unique': 849, 'test_unique': 849},\n",
       " 'state': {'train_unique': 50, 'test_unique': 50},\n",
       " 'job': {'train_unique': 478, 'test_unique': 478},\n",
       " 'dob': {'train_unique': 910, 'test_unique': 910},\n",
       " 'trans_num': {'train_unique': 555719, 'test_unique': 555719}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "unique_counts = {}\n",
    "for col in categorical_features:\n",
    "    unique_counts[col] = {\n",
    "        \"train_unique\": train_df[col].nunique(),\n",
    "        \"test_unique\": test_df[col].nunique()\n",
    "    }\n",
    "\n",
    "\n",
    "unique_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0978cf03-5a5f-4117-8439-c584b5381ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# -----------------------------\n",
    "# One-Hot Encoding \n",
    "# -----------------------------\n",
    "one_hot_features = [\"category\", \"gender\", \"state\"]\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns=one_hot_features, drop_first=False)\n",
    "test_df = pd.get_dummies(test_df, columns=one_hot_features, drop_first=False)\n",
    "#test_df\n",
    "test_df = test_df.reindex(columns=train_df.columns, fill_value=0)\n",
    "\n",
    "# -----------------------------\n",
    "# Label Encoding \n",
    "# -----------------------------\n",
    "label_features = [\"merchant\", \"first\", \"last\", \"street\", \"city\", \"job\", \"dob\"]\n",
    "\n",
    "for col in label_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(pd.concat([train_df[col], test_df[col]], axis=0))\n",
    "    \n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "\n",
    "# -----------------------------\n",
    "# high-cardinality features\n",
    "# -----------------------------\n",
    "\n",
    "train_df['trans_date_trans_time'] = pd.to_datetime(train_df['trans_date_trans_time'])\n",
    "test_df['trans_date_trans_time'] = pd.to_datetime(test_df['trans_date_trans_time'])\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['trans_hour'] = df['trans_date_trans_time'].dt.hour\n",
    "    df['trans_day'] = df['trans_date_trans_time'].dt.day\n",
    "    df['trans_month'] = df['trans_date_trans_time'].dt.month\n",
    "    df['trans_weekday'] = df['trans_date_trans_time'].dt.weekday\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7b10b-5cd4-4878-8f3f-cc55c4562863",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95eb857c-0af7-4b20-b074-90248412ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "numerical_features = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_df[numerical_features] = scaler.fit_transform(train_df[numerical_features])\n",
    "test_df[numerical_features] = scaler.transform(test_df[numerical_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39330ae-77c0-4bff-8f4e-702e2eb6bf70",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "210012c5-487c-47bd-9bce-3c6d3c9bf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract age\n",
    "\n",
    "from datetime import datetime\n",
    "def add_age_feature(df):\n",
    "    df['dob'] = pd.to_datetime(df['dob'], errors='coerce')\n",
    "    today_year = datetime.today().year\n",
    "    df['age'] = today_year - df['dob'].dt.year\n",
    "\n",
    "    df['age_group'] = pd.cut(\n",
    "        df['age'],\n",
    "        bins=[0, 25, 40, 60, 100],\n",
    "        labels=['0', '1', '2', '3'] # 0: young 1:adult 2: mature 3:senior\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = add_age_feature(train_df)\n",
    "test_df = add_age_feature(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d851ecf-2b0d-4cd4-b4ad-d2bf78642aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>amt_per_capita</th>\n",
       "      <th>amt_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096147</td>\n",
       "      <td>0.052815</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.400029</td>\n",
       "      <td>0.328408</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.446164</td>\n",
       "      <td>0.274509</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.499884</td>\n",
       "      <td>0.300219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.108143</td>\n",
       "      <td>0.081246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        amt  amt_per_capita amt_category\n",
       "0  0.096147        0.052815            1\n",
       "1  0.400029        0.328408            2\n",
       "2  0.446164        0.274509            2\n",
       "3  0.499884        0.300219            2\n",
       "4  0.108143        0.081246            1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transaction amount per city pop and categorization into bins\n",
    "def add_transaction_features(df):\n",
    "    \n",
    "    #Transaction amount per city pop\n",
    "    df[\"amt_per_capita\"] = df[\"amt\"] / (df[\"city_pop\"] + 1)  \n",
    "    \n",
    "    #Transaction amount bins \n",
    "    df[\"amt_category\"] = pd.qcut(df[\"amt\"], q=3, labels=[\"1\", \"2\", \"3\"]) #1:low 2:medium 3:high\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply to both train and test\n",
    "train_df = add_transaction_features(train_df)\n",
    "test_df = add_transaction_features(test_df)\n",
    "\n",
    "train_df[[\"amt\", \"amt_per_capita\", \"amt_category\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94b0a3a9-2819-4ec6-9740-e97ccc643511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance between customer and merchant (3 methods)\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371  \n",
    "    return c * r\n",
    "\n",
    "def add_distance_features(df):\n",
    "    df[\"haversine_dist\"] = haversine_distance(\n",
    "        df[\"lat\"], df[\"long\"], df[\"merch_lat\"], df[\"merch_long\"]\n",
    "    )\n",
    "    \n",
    "    df[\"manhattan_dist\"] = (\n",
    "        abs(df[\"lat\"] - df[\"merch_lat\"]) + abs(df[\"long\"] - df[\"merch_long\"])\n",
    "    )\n",
    "    \n",
    "    df[\"euclidean_dist\"] = np.sqrt(\n",
    "        (df[\"lat\"] - df[\"merch_lat\"])**2 + (df[\"long\"] - df[\"merch_long\"])**2\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = add_distance_features(train_df)\n",
    "test_df = add_distance_features(test_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e97773d-4a82-4687-982f-036d3229ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer level aggregation features \n",
    "def add_customer_agg_features(train_df, test_df):\n",
    "    customer_stats = train_df.groupby(\"cc_num\").agg(\n",
    "        avg_transaction_amt=(\"amt\", \"mean\"),\n",
    "        std_transaction_amt=(\"amt\", \"std\"),\n",
    "        transaction_count=(\"amt\", \"count\")\n",
    "    ).reset_index()\n",
    "    \n",
    "    train_df = train_df.merge(customer_stats, on=\"cc_num\", how=\"left\")\n",
    "    \n",
    "    test_df = test_df.merge(customer_stats, on=\"cc_num\", how=\"left\")\n",
    "    \n",
    "    train_df[\"std_transaction_amt\"].fillna(0, inplace=True)\n",
    "    test_df[\"std_transaction_amt\"].fillna(0, inplace=True)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "train_df, test_df = add_customer_agg_features(train_df, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6526bbda-3edd-4d74-a303-8b3b81280eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>amt_per_capita</th>\n",
       "      <th>amt_category</th>\n",
       "      <th>haversine_dist</th>\n",
       "      <th>manhattan_dist</th>\n",
       "      <th>euclidean_dist</th>\n",
       "      <th>avg_transaction_amt</th>\n",
       "      <th>std_transaction_amt</th>\n",
       "      <th>transaction_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-21 12:14:25</td>\n",
       "      <td>4.589232e-04</td>\n",
       "      <td>319</td>\n",
       "      <td>0.096147</td>\n",
       "      <td>151</td>\n",
       "      <td>115</td>\n",
       "      <td>341</td>\n",
       "      <td>157</td>\n",
       "      <td>0.283305</td>\n",
       "      <td>0.350678</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Mature</td>\n",
       "      <td>0.052815</td>\n",
       "      <td>1</td>\n",
       "      <td>2.022390</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>0.399822</td>\n",
       "      <td>0.187530</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-21 12:14:33</td>\n",
       "      <td>7.156895e-04</td>\n",
       "      <td>591</td>\n",
       "      <td>0.400029</td>\n",
       "      <td>163</td>\n",
       "      <td>457</td>\n",
       "      <td>354</td>\n",
       "      <td>16</td>\n",
       "      <td>0.838654</td>\n",
       "      <td>0.570540</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Mature</td>\n",
       "      <td>0.328408</td>\n",
       "      <td>2</td>\n",
       "      <td>3.689786</td>\n",
       "      <td>0.039251</td>\n",
       "      <td>0.033183</td>\n",
       "      <td>0.372070</td>\n",
       "      <td>0.189823</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-21 12:14:53</td>\n",
       "      <td>7.207342e-04</td>\n",
       "      <td>611</td>\n",
       "      <td>0.446164</td>\n",
       "      <td>24</td>\n",
       "      <td>249</td>\n",
       "      <td>865</td>\n",
       "      <td>61</td>\n",
       "      <td>0.105945</td>\n",
       "      <td>0.582725</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Mature</td>\n",
       "      <td>0.274509</td>\n",
       "      <td>2</td>\n",
       "      <td>3.254732</td>\n",
       "      <td>0.036420</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>0.448421</td>\n",
       "      <td>0.190908</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-21 12:15:15</td>\n",
       "      <td>7.194732e-04</td>\n",
       "      <td>222</td>\n",
       "      <td>0.499884</td>\n",
       "      <td>42</td>\n",
       "      <td>457</td>\n",
       "      <td>320</td>\n",
       "      <td>764</td>\n",
       "      <td>0.319498</td>\n",
       "      <td>0.163981</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Mature</td>\n",
       "      <td>0.300219</td>\n",
       "      <td>2</td>\n",
       "      <td>1.683320</td>\n",
       "      <td>0.019047</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.392666</td>\n",
       "      <td>0.181532</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-21 12:15:17</td>\n",
       "      <td>7.064345e-04</td>\n",
       "      <td>292</td>\n",
       "      <td>0.108143</td>\n",
       "      <td>247</td>\n",
       "      <td>261</td>\n",
       "      <td>548</td>\n",
       "      <td>247</td>\n",
       "      <td>0.490300</td>\n",
       "      <td>0.706585</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Mature</td>\n",
       "      <td>0.081246</td>\n",
       "      <td>1</td>\n",
       "      <td>3.964745</td>\n",
       "      <td>0.050211</td>\n",
       "      <td>0.035657</td>\n",
       "      <td>0.389118</td>\n",
       "      <td>0.184189</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555714</th>\n",
       "      <td>2020-12-31 23:59:07</td>\n",
       "      <td>6.109391e-06</td>\n",
       "      <td>507</td>\n",
       "      <td>0.454531</td>\n",
       "      <td>235</td>\n",
       "      <td>315</td>\n",
       "      <td>531</td>\n",
       "      <td>443</td>\n",
       "      <td>0.630382</td>\n",
       "      <td>0.576504</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Mature</td>\n",
       "      <td>0.359445</td>\n",
       "      <td>2</td>\n",
       "      <td>2.362405</td>\n",
       "      <td>0.022370</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>0.406393</td>\n",
       "      <td>0.191628</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555715</th>\n",
       "      <td>2020-12-31 23:59:09</td>\n",
       "      <td>7.124010e-04</td>\n",
       "      <td>264</td>\n",
       "      <td>0.589709</td>\n",
       "      <td>171</td>\n",
       "      <td>424</td>\n",
       "      <td>540</td>\n",
       "      <td>401</td>\n",
       "      <td>0.773423</td>\n",
       "      <td>0.180228</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Mature</td>\n",
       "      <td>0.366367</td>\n",
       "      <td>3</td>\n",
       "      <td>3.085534</td>\n",
       "      <td>0.039097</td>\n",
       "      <td>0.027749</td>\n",
       "      <td>0.342446</td>\n",
       "      <td>0.187052</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555716</th>\n",
       "      <td>2020-12-31 23:59:15</td>\n",
       "      <td>1.204176e-03</td>\n",
       "      <td>496</td>\n",
       "      <td>0.553152</td>\n",
       "      <td>18</td>\n",
       "      <td>239</td>\n",
       "      <td>126</td>\n",
       "      <td>104</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.773833</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Mature</td>\n",
       "      <td>0.386023</td>\n",
       "      <td>3</td>\n",
       "      <td>2.202653</td>\n",
       "      <td>0.027995</td>\n",
       "      <td>0.019810</td>\n",
       "      <td>0.463466</td>\n",
       "      <td>0.183103</td>\n",
       "      <td>1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555717</th>\n",
       "      <td>2020-12-31 23:59:24</td>\n",
       "      <td>8.051039e-07</td>\n",
       "      <td>75</td>\n",
       "      <td>0.219774</td>\n",
       "      <td>111</td>\n",
       "      <td>342</td>\n",
       "      <td>663</td>\n",
       "      <td>476</td>\n",
       "      <td>0.835016</td>\n",
       "      <td>0.719476</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Mature</td>\n",
       "      <td>0.191892</td>\n",
       "      <td>1</td>\n",
       "      <td>1.463654</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>0.013164</td>\n",
       "      <td>0.387738</td>\n",
       "      <td>0.192601</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555718</th>\n",
       "      <td>2020-12-31 23:59:34</td>\n",
       "      <td>8.354046e-04</td>\n",
       "      <td>125</td>\n",
       "      <td>0.434842</td>\n",
       "      <td>280</td>\n",
       "      <td>145</td>\n",
       "      <td>778</td>\n",
       "      <td>224</td>\n",
       "      <td>0.727489</td>\n",
       "      <td>0.409515</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Mature</td>\n",
       "      <td>0.251410</td>\n",
       "      <td>2</td>\n",
       "      <td>1.785006</td>\n",
       "      <td>0.017221</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>0.384739</td>\n",
       "      <td>0.189152</td>\n",
       "      <td>1090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555719 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       trans_date_trans_time        cc_num  merchant       amt  first  last  \\\n",
       "0        2020-06-21 12:14:25  4.589232e-04       319  0.096147    151   115   \n",
       "1        2020-06-21 12:14:33  7.156895e-04       591  0.400029    163   457   \n",
       "2        2020-06-21 12:14:53  7.207342e-04       611  0.446164     24   249   \n",
       "3        2020-06-21 12:15:15  7.194732e-04       222  0.499884     42   457   \n",
       "4        2020-06-21 12:15:17  7.064345e-04       292  0.108143    247   261   \n",
       "...                      ...           ...       ...       ...    ...   ...   \n",
       "555714   2020-12-31 23:59:07  6.109391e-06       507  0.454531    235   315   \n",
       "555715   2020-12-31 23:59:09  7.124010e-04       264  0.589709    171   424   \n",
       "555716   2020-12-31 23:59:15  1.204176e-03       496  0.553152     18   239   \n",
       "555717   2020-12-31 23:59:24  8.051039e-07        75  0.219774    111   342   \n",
       "555718   2020-12-31 23:59:34  8.354046e-04       125  0.434842    280   145   \n",
       "\n",
       "        street  city       zip       lat  ...  age  age_group  amt_per_capita  \\\n",
       "0          341   157  0.283305  0.350678  ...   55     Mature        0.052815   \n",
       "1          354    16  0.838654  0.570540  ...   55     Mature        0.328408   \n",
       "2          865    61  0.105945  0.582725  ...   55     Mature        0.274509   \n",
       "3          320   764  0.319498  0.163981  ...   55     Mature        0.300219   \n",
       "4          548   247  0.490300  0.706585  ...   55     Mature        0.081246   \n",
       "...        ...   ...       ...       ...  ...  ...        ...             ...   \n",
       "555714     531   443  0.630382  0.576504  ...   55     Mature        0.359445   \n",
       "555715     540   401  0.773423  0.180228  ...   55     Mature        0.366367   \n",
       "555716     126   104  0.993939  0.773833  ...   55     Mature        0.386023   \n",
       "555717     663   476  0.835016  0.719476  ...   55     Mature        0.191892   \n",
       "555718     778   224  0.727489  0.409515  ...   55     Mature        0.251410   \n",
       "\n",
       "       amt_category haversine_dist  manhattan_dist  euclidean_dist  \\\n",
       "0                 1       2.022390        0.020412        0.018188   \n",
       "1                 2       3.689786        0.039251        0.033183   \n",
       "2                 2       3.254732        0.036420        0.029272   \n",
       "3                 2       1.683320        0.019047        0.015139   \n",
       "4                 1       3.964745        0.050211        0.035657   \n",
       "...             ...            ...             ...             ...   \n",
       "555714            2       2.362405        0.022370        0.021246   \n",
       "555715            3       3.085534        0.039097        0.027749   \n",
       "555716            3       2.202653        0.027995        0.019810   \n",
       "555717            1       1.463654        0.018181        0.013164   \n",
       "555718            2       1.785006        0.017221        0.016053   \n",
       "\n",
       "        avg_transaction_amt  std_transaction_amt  transaction_count  \n",
       "0                  0.399822             0.187530                640  \n",
       "1                  0.372070             0.189823                837  \n",
       "2                  0.448421             0.190908               1073  \n",
       "3                  0.392666             0.181532                663  \n",
       "4                  0.389118             0.184189                891  \n",
       "...                     ...                  ...                ...  \n",
       "555714             0.406393             0.191628                628  \n",
       "555715             0.342446             0.187052               1105  \n",
       "555716             0.463466             0.183103               1079  \n",
       "555717             0.387738             0.192601                883  \n",
       "555718             0.384739             0.189152               1090  \n",
       "\n",
       "[555719 rows x 99 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e5a1fa-077e-4f1c-a8a0-be54e796024a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
