{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c77da2f-1356-417b-be28-c3eaad7a7011",
   "metadata": {},
   "source": [
    "<p style=\"background-color: #0055A4; font-size: 48px; font-weight: bold; color: white; padding: 20px; text-align: center;\">\n",
    "ðŸ§¹ Data Cleaning \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eeccbbd-a357-410b-a8de-883d94a36657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as stats\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import missingno as msno\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import skew, shapiro\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import shap\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from prettytable import PrettyTable\n",
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6e5ec07-2c78-408b-8356-d3788a5a61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "train_df = pd.read_csv('C:/Users/Mega-Pc/Freelance/data/fraudTrain.csv', delimiter=',', encoding='utf-8',index_col=0)\n",
    "test_df = pd.read_csv('C:/Users/Mega-Pc/Freelance/data/fraudTest.csv', delimiter=',', encoding='utf-8',index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a853c7-cf5f-4ea0-9943-d66d33a84a41",
   "metadata": {},
   "source": [
    "## ðŸ”„ Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1ab848-1386-4332-a353-44543eff0e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records: 0\n"
     ]
    }
   ],
   "source": [
    "#train_df\n",
    "duplicate_count = train_df.duplicated().sum()\n",
    "print(f'Number of duplicate records: {duplicate_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f9d198e-2a67-4682-b208-d6f02cae58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records: 0\n"
     ]
    }
   ],
   "source": [
    "#train_df\n",
    "duplicate_count = test_df.duplicated().sum()\n",
    "print(f'Number of duplicate records: {duplicate_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d88f733-0e4d-4857-9747-91a108f2e4bc",
   "metadata": {},
   "source": [
    "## âœ¨ Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f26df6-e67c-4ebc-9fff-8a787293e886",
   "metadata": {},
   "source": [
    "## Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3b27ee5-d376-446b-a63b-aa5f2c91691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df + test_df\n",
    "skewed_cols = ['amt','city_pop']\n",
    "for col in skewed_cols:\n",
    "    train_df[col] = np.log1p(train_df[col])  \n",
    "    test_df[col] = np.log1p(test_df[col])\n",
    "     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb65409-e551-4ff2-bb14-e91f326eb822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amt</td>\n",
       "      <td>-0.298852</td>\n",
       "      <td>-0.527247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_pop</td>\n",
       "      <td>0.606094</td>\n",
       "      <td>-0.301258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  Skewness  Kurtosis\n",
       "0       amt -0.298852 -0.527247\n",
       "1  city_pop  0.606094 -0.301258"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "for var in  skewed_cols:\n",
    "    skewness = stats.skew(train_df[var])\n",
    "    kurtosis = stats.kurtosis(train_df[var])\n",
    "    \n",
    "    results.append({\n",
    "        'Feature':  var ,\n",
    "        'Skewness': skewness,\n",
    "        'Kurtosis': kurtosis\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a81ba-fa90-4190-94cc-273b77091610",
   "metadata": {},
   "source": [
    "## Handle outliers by capping them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37972283-18ab-4897-b234-78984b817833",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_vars_filtered = [\n",
    "    \"amt\",\n",
    "    \"zip\",\n",
    "    \"lat\",\n",
    "    \"long\",\n",
    "    \"city_pop\",\n",
    "    \"unix_time\",\n",
    "    \"merch_lat\",\n",
    "    \"merch_long\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5809721-0468-4e5b-a5dc-7e4ca9de817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature   Lower Bound   Upper Bound  Outliers Count  Total Points\n",
      "0         amt -7.348234e-01  7.532865e+00             818       1296675\n",
      "1         zip -4.247050e+04  1.407495e+05               0       1296675\n",
      "2         lat  2.364065e+01  5.292025e+01            4679       1296675\n",
      "3        long -1.217580e+02 -5.519800e+01           49922       1296675\n",
      "4    city_pop  1.650397e+00  1.488145e+01            4168       1296675\n",
      "5   unix_time  1.307799e+09  1.390337e+09               0       1296675\n",
      "6   merch_lat  2.389818e+01  5.279255e+01            4967       1296675\n",
      "7  merch_long -1.218880e+02 -5.524608e+01           41994       1296675\n"
     ]
    }
   ],
   "source": [
    "#train_df\n",
    "outliers_info = []\n",
    "\n",
    "for col in numerical_vars_filtered:\n",
    "    Q1 = train_df[col].quantile(0.25)\n",
    "    Q3 = train_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = train_df[(train_df[col] < lower_bound) | (train_df[col] > upper_bound)]\n",
    "    \n",
    "    outliers_info.append({\n",
    "        'Feature': col,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound,\n",
    "        'Outliers Count': len(outliers),\n",
    "        'Total Points': len(train_df)\n",
    "    })\n",
    "\n",
    "outliers_df = pd.DataFrame(outliers_info)\n",
    "print(outliers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85b89a0a-46ac-411c-aa7c-471fb4097ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[column] = np.clip(df[column], lower_bound, upper_bound)\n",
    "    return df\n",
    "\n",
    "columns_with_outliers = [\n",
    "    \"amt\",\n",
    "    \"lat\",\n",
    "    \"long\",\n",
    "    \"city_pop\",\n",
    "    \"merch_lat\",\n",
    "    \"merch_long\"\n",
    "]\n",
    "\n",
    "for col in columns_with_outliers:\n",
    "    train_df = handle_outliers(train_df, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4ce4f36-8e4e-4b75-a858-151f127f27ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature   Lower Bound   Upper Bound  Outliers Count  Total Points\n",
      "0         amt -7.348234e-01  7.532865e+00               0       1296675\n",
      "1         zip -4.247050e+04  1.407495e+05               0       1296675\n",
      "2         lat  2.364065e+01  5.292025e+01               0       1296675\n",
      "3        long -1.217580e+02 -5.519800e+01               0       1296675\n",
      "4    city_pop  1.650397e+00  1.488145e+01               0       1296675\n",
      "5   unix_time  1.307799e+09  1.390337e+09               0       1296675\n",
      "6   merch_lat  2.389818e+01  5.279255e+01               0       1296675\n",
      "7  merch_long -1.218880e+02 -5.524608e+01               0       1296675\n"
     ]
    }
   ],
   "source": [
    "# results after capping outliers\n",
    "outliers_info = []\n",
    "\n",
    "for col in numerical_vars_filtered:\n",
    "    Q1 = train_df[col].quantile(0.25)\n",
    "    Q3 = train_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = train_df[(train_df[col] < lower_bound) | (train_df[col] > upper_bound)]\n",
    "    \n",
    "    outliers_info.append({\n",
    "        'Feature': col,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound,\n",
    "        'Outliers Count': len(outliers),\n",
    "        'Total Points': len(train_df)\n",
    "    })\n",
    "\n",
    "outliers_df = pd.DataFrame(outliers_info)\n",
    "print(outliers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d6714c6-349d-42b6-bd99-59611ffd6e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature   Lower Bound   Upper Bound  Outliers Count  Total Points\n",
      "0         amt -7.372033e-01  7.531819e+00             402       1296675\n",
      "1         zip -4.228650e+04  1.405895e+05               0       1296675\n",
      "2         lat  2.383005e+01  5.273365e+01            1933       1296675\n",
      "3        long -1.217322e+02 -5.524100e+01           21104       1296675\n",
      "4    city_pop  1.691879e+00  1.480513e+01            1697       1296675\n",
      "5   unix_time  1.361271e+09  1.400625e+09               0       1296675\n",
      "6   merch_lat  2.395701e+01  5.275246e+01            2090       1296675\n",
      "7  merch_long -1.218659e+02 -5.530390e+01           17926       1296675\n"
     ]
    }
   ],
   "source": [
    "#test_df\n",
    "outliers_info = []\n",
    "\n",
    "for col in numerical_vars_filtered:\n",
    "    Q1 = test_df[col].quantile(0.25)\n",
    "    Q3 = test_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = test_df[(test_df[col] < lower_bound) | (test_df[col] > upper_bound)]\n",
    "    \n",
    "    outliers_info.append({\n",
    "        'Feature': col,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound,\n",
    "        'Outliers Count': len(outliers),\n",
    "        'Total Points': len(train_df)\n",
    "    })\n",
    "\n",
    "outliers_df = pd.DataFrame(outliers_info)\n",
    "print(outliers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60b25697-197f-4920-834f-d967dca90328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[column] = np.clip(df[column], lower_bound, upper_bound)\n",
    "    return df\n",
    "\n",
    "columns_with_outliers = [\n",
    "    \"amt\",\n",
    "    \"lat\",\n",
    "    \"long\",\n",
    "    \"city_pop\",\n",
    "    \"merch_lat\",\n",
    "    \"merch_long\"\n",
    "]\n",
    "\n",
    "for col in columns_with_outliers:\n",
    "    train_df = handle_outliers(test_df, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6b52c2b-b59e-403f-90fa-4a5062165820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature   Lower Bound   Upper Bound  Outliers Count  Total Points\n",
      "0         amt -7.372033e-01  7.531819e+00               0        555719\n",
      "1         zip -4.228650e+04  1.405895e+05               0        555719\n",
      "2         lat  2.383005e+01  5.273365e+01               0        555719\n",
      "3        long -1.217322e+02 -5.524100e+01               0        555719\n",
      "4    city_pop  1.691879e+00  1.480513e+01               0        555719\n",
      "5   unix_time  1.361271e+09  1.400625e+09               0        555719\n",
      "6   merch_lat  2.395701e+01  5.275246e+01               0        555719\n",
      "7  merch_long -1.218659e+02 -5.530390e+01               0        555719\n"
     ]
    }
   ],
   "source": [
    "# results after capping outliers\n",
    "outliers_info = []\n",
    "\n",
    "for col in numerical_vars_filtered:\n",
    "    Q1 = test_df[col].quantile(0.25)\n",
    "    Q3 = test_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = test_df[(test_df[col] < lower_bound) | (test_df[col] > upper_bound)]\n",
    "    \n",
    "    outliers_info.append({\n",
    "        'Feature': col,\n",
    "        'Lower Bound': lower_bound,\n",
    "        'Upper Bound': upper_bound,\n",
    "        'Outliers Count': len(outliers),\n",
    "        'Total Points': len(train_df)\n",
    "    })\n",
    "\n",
    "outliers_df = pd.DataFrame(outliers_info)\n",
    "print(outliers_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2699d6-16a7-4350-883c-cf321637e4f5",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16de60dd-523d-451b-b1d8-d759ed9641aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trans_date_trans_time': {'train_unique': 544760, 'test_unique': 544760},\n",
       " 'merchant': {'train_unique': 693, 'test_unique': 693},\n",
       " 'category': {'train_unique': 14, 'test_unique': 14},\n",
       " 'first': {'train_unique': 341, 'test_unique': 341},\n",
       " 'last': {'train_unique': 471, 'test_unique': 471},\n",
       " 'gender': {'train_unique': 2, 'test_unique': 2},\n",
       " 'street': {'train_unique': 924, 'test_unique': 924},\n",
       " 'city': {'train_unique': 849, 'test_unique': 849},\n",
       " 'state': {'train_unique': 50, 'test_unique': 50},\n",
       " 'job': {'train_unique': 478, 'test_unique': 478},\n",
       " 'dob': {'train_unique': 910, 'test_unique': 910},\n",
       " 'trans_num': {'train_unique': 555719, 'test_unique': 555719}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "unique_counts = {}\n",
    "for col in categorical_features:\n",
    "    unique_counts[col] = {\n",
    "        \"train_unique\": train_df[col].nunique(),\n",
    "        \"test_unique\": test_df[col].nunique()\n",
    "    }\n",
    "\n",
    "\n",
    "unique_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0978cf03-5a5f-4117-8439-c584b5381ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# -----------------------------\n",
    "# 1. One-Hot Encoding \n",
    "# -----------------------------\n",
    "one_hot_features = [\"category\", \"gender\", \"state\"]\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns=one_hot_features, drop_first=False)\n",
    "test_df = pd.get_dummies(test_df, columns=one_hot_features, drop_first=False)\n",
    "#test_df\n",
    "test_df = test_df.reindex(columns=train_df.columns, fill_value=0)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Label Encoding \n",
    "# -----------------------------\n",
    "label_features = [\"merchant\", \"first\", \"last\", \"street\", \"city\", \"job\", \"dob\"]\n",
    "\n",
    "for col in label_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(pd.concat([train_df[col], test_df[col]], axis=0))\n",
    "    \n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "\n",
    "# -----------------------------\n",
    "# 3. high-cardinality features\n",
    "# -----------------------------\n",
    "\n",
    "train_df['trans_date_trans_time'] = pd.to_datetime(train_df['trans_date_trans_time'])\n",
    "test_df['trans_date_trans_time'] = pd.to_datetime(test_df['trans_date_trans_time'])\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['trans_hour'] = df['trans_date_trans_time'].dt.hour\n",
    "    df['trans_day'] = df['trans_date_trans_time'].dt.day\n",
    "    df['trans_month'] = df['trans_date_trans_time'].dt.month\n",
    "    df['trans_weekday'] = df['trans_date_trans_time'].dt.weekday\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7bf18b-132a-4672-8bea-8c49bac8bb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
